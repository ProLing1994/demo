#include <algorithm>
#include <iostream>
#include <map>
#include <memory>
#include <vector>
#include <string>

#include "common/utils/csrc/file_system.h"
#include "gflags/gflags.h"
#include "glog/logging.h"
#include "opencv2/opencv.hpp"

#include "inference_engine.hpp"

using namespace InferenceEngine;

DEFINE_string(image_folder, "/home/huanyuan/code/images",
  "The folder containing the image data");
DEFINE_string(model_path, "/home/huanyuan/code/models/ssd_License_plate_mobilenetv2.xml",
  "The network model path");
DEFINE_string(output_folder, "/home/huanyuan/code/images_result",
  "The folder containing the output results");

int main(int argc, char *argv[]) {
	try {
		google::ParseCommandLineFlags(&argc, &argv, true);
		google::InitGoogleLogging(argv[0]);

		// 1. Read input
		std::vector<std::string> image_subfolder;
		std::vector<std::string> image_names;
		yh_common::list_directory(FLAGS_image_folder.c_str(), image_subfolder, image_names);
		CHECK_GT(image_names.size(), 0);

		// 2. Load inference engine
		LOG(INFO) << "Loading Inference Engine";
		Core ie;
		ie.GetVersions("CPU");

		// 3. Read IR Generated by ModelOptimizer (.xml and .bin files)
		std::string binFileName = FLAGS_model_path.substr(0, FLAGS_model_path.rfind('.')) + ".bin";
		LOG(INFO) << "Loading network files: \n\t" << FLAGS_model_path << "\n\t" << binFileName;
		CNNNetwork network = ie.ReadNetwork(FLAGS_model_path.c_str());
		LOG(INFO) << "Batch size is " << std::to_string(network.getBatchSize());

		// 4. Prepare input blobs
		LOG(INFO) << "Preparing input blobs";
		InputsDataMap inputsInfo(network.getInputsInfo());
		for (auto & item : inputsInfo) {
			item.second->setPrecision(Precision::U8);
			item.second->setLayout(Layout::NCHW);
		}
		InputInfo::Ptr inputInfo = inputsInfo.begin()->second;
		std::string imageInputName = inputsInfo.begin()->first;

		// 5. Prepare output blobs 
		LOG(INFO) << "Preparing output blobs";
		OutputsDataMap outputsInfo(network.getOutputsInfo());
		DataPtr outputInfo = outputsInfo.begin()->second;
		std::string outputName = outputInfo->getName();	
		outputInfo->setPrecision(Precision::FP32);
		CHECK_NOTNULL(outputInfo);

		const SizeVector outputDims = outputInfo->getTensorDesc().getDims();
		const int maxProposalCount = outputDims[2];
		const int objectSize = outputDims[3];

		if (objectSize != 7) {
			throw std::logic_error("Output item should have 7 as a last dimension");
		}

		if (outputDims.size() != 4) {
			throw std::logic_error("Incorrect output dimensions for SSD model");
		}

		// 6. Loading model to the device 
		LOG(INFO) << "Loading model to the device";
		ExecutableNetwork executable_network = ie.LoadNetwork(network, "CPU");

		// 7. Create infer request 
		LOG(INFO) << "Create infer request";
		InferRequest infer_request = executable_network.CreateInferRequest();	

		for (auto & i : image_names) {
			// 8. Prepare input
			std::string image_path = FLAGS_image_folder + "/" + i;
			std::string output_image_path = FLAGS_output_folder + "/" + i;

			cv::Mat img_src = cv::imread(image_path.c_str(), 1);
			int width = img_src.cols;
  		int height = img_src.rows;

  		// resize
  		cv::Mat img_resized(img_src);
  		cv::resize(img_src, img_resized, cv::Size(inputInfo->getTensorDesc().getDims()[3], inputInfo->getTensorDesc().getDims()[2]));

			std::shared_ptr<unsigned char> img_resized_data;
			int size = img_resized.cols * img_resized.rows * img_resized.channels();
			img_resized_data.reset(new unsigned char[size], std::default_delete<unsigned char[]>());
			for (int id = 0; id < size; ++id) {
					img_resized_data.get()[id] = img_resized.data[id];
			}

			/** Creating input blob **/	
			Blob::Ptr imageInput = infer_request.GetBlob(imageInputName);

			/** Filling input tensor with images. First b channel, then g and r channels **/
			MemoryBlob::Ptr mimage = as<MemoryBlob>(imageInput);
			if (!mimage) {
					LOG(ERROR) << "We expect image blob to be inherited from MemoryBlob, but by fact we were not able "
							"to cast imageInput to MemoryBlob";
					return 1;
			}

			// locked memory holder should be alive all time while access to its buffer happens
			auto minputHolder = mimage->wmap();
			size_t num_channels = mimage->getTensorDesc().getDims()[1];
			size_t image_size = mimage->getTensorDesc().getDims()[3] * mimage->getTensorDesc().getDims()[2];
			unsigned char *data = minputHolder.as<unsigned char *>();

			/** Iterate over all input images **/
			for (size_t image_id = 0; image_id < network.getBatchSize(); ++image_id) {
					/** Iterate over all pixel in image (b,g,r) **/
					for (size_t pid = 0; pid < image_size; pid++) {
							/** Iterate over all channels **/
							for (size_t ch = 0; ch < num_channels; ++ch) {
									/**          [images stride + channels stride + pixel id ] all in bytes            **/
									data[image_id * image_size * num_channels + ch * image_size + pid] = img_resized_data.get()[pid*num_channels + ch];
							}
					}
			}

			// 9. Do inference 
			LOG(INFO) << "Start inference";
			infer_request.Infer();	

			// 10. Process output
			LOG(INFO) << "Processing output blobs";
			const Blob::Ptr output_blob = infer_request.GetBlob(outputName);
			MemoryBlob::CPtr moutput = as<MemoryBlob>(output_blob);
			if (!moutput) {
					throw std::logic_error("We expect output to be inherited from MemoryBlob, "
																	"but by fact we were not able to cast output to MemoryBlob");
			}

			// locked memory holder should be alive all time while access to its buffer happens
			auto moutputHolder = moutput->rmap();
			const float *detection = moutputHolder.as<const PrecisionTrait<Precision::FP32>::value_type *>();

			std::vector<std::vector<int> > boxes(network.getBatchSize());
			std::vector<std::vector<int> > classes(network.getBatchSize());

			/* Each detection has image_id that denotes processed image */
			for (int curProposal = 0; curProposal < maxProposalCount; curProposal++) {
				auto image_id = static_cast<int>(detection[curProposal * objectSize + 0]);
				if (image_id < 0) {
						break;
				}

				float confidence = detection[curProposal * objectSize + 2];
				auto label = static_cast<int>(detection[curProposal * objectSize + 1]);
				auto xmin = static_cast<int>(detection[curProposal * objectSize + 3] * width);
				auto ymin = static_cast<int>(detection[curProposal * objectSize + 4] * height);
				auto xmax = static_cast<int>(detection[curProposal * objectSize + 5] * width);
				auto ymax = static_cast<int>(detection[curProposal * objectSize + 6] * height);

				if (confidence > 0.5) {
						/** Drawing only objects with >50% probability **/
						classes[image_id].push_back(label);
						boxes[image_id].push_back(xmin);
						boxes[image_id].push_back(ymin);
						boxes[image_id].push_back(xmax - xmin);
						boxes[image_id].push_back(ymax - ymin);
						LOG(INFO) << "[" << curProposal << "," << label << "] element, prob = " << confidence <<	
							"    (" << xmin << "," << ymin << ")-(" << xmax << "," << ymax << ")" << " batch id : " << image_id;
				}
				std::cout << std::endl;
			}

			for (size_t batch_id = 0; batch_id < network.getBatchSize(); ++batch_id) {
					cv::Rect location_;
					if(!boxes[batch_id].empty()) {
						location_.x = boxes[batch_id][0];
						location_.y = boxes[batch_id][1];
						location_.width = boxes[batch_id][2];
						location_.height = boxes[batch_id][3];
						cv::rectangle(img_src, location_, cv::Scalar(0, 0, 255), 2);
					}
					cv::imwrite(output_image_path, img_src);
			}
		}
	}
	catch (const std::exception& error) {
		LOG(ERROR) << error.what();
		return 1;
	}
	catch (...) {
		LOG(ERROR) << "Unknown/internal exception happened.";
		return 1;
	}

	LOG(INFO) << "Execution successful";
	LOG(INFO) << "This sample is an API example, for any performance measurements please use the dedicated benchmark_app tool";
	return 0;
}
